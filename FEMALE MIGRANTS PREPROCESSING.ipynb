{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90dccd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.nl.stop_words import STOP_WORDS\n",
    "import re\n",
    "\n",
    "# Download NL Core News LG model for Dutch language\n",
    "try:\n",
    "    nlp = spacy.load('nl_core_news_lg')\n",
    "except:\n",
    "    !python -m spacy download nl_core_news_lg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b38ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters, digits, stand alone letters, and non-word symbols\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]|(?<!\\w)\\w(?!\\w)', '', text)\n",
    "    \n",
    "    # Keep expressions like '24-jarige'\n",
    "    cleaned_text = re.sub(r'\\b(\\d+-[a-zA-Z]+)\\b', r'\\1', cleaned_text)\n",
    "    \n",
    "    assert clean_text('24-jarige') == '24-jarige'\n",
    "    assert clean_text('1-1-1990').strip() == ''\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0d4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Function for lowercasing text\n",
    "\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4236622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 Test the lowercase_text function\n",
    "assert lowercase_text('Hello World') == 'hello world'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91bebc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 Function for tokenization\n",
    "def tokenize_text(text):\n",
    "    return [token.text for token in nlp(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080a7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 Test the tokenize_text function with Dutch words\n",
    "assert tokenize_text('Dit is een testzin.') == ['Dit', 'is', 'een', 'testzin', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ffeb940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 Function for removing stop words\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token not in STOP_WORDS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74edc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 Test the remove_stopwords function with Dutch words\n",
    "assert remove_stopwords(['Dit', 'is', 'een', 'testzin', '.']) == ['Dit', 'testzin', '.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e08ad42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9  Function for lemmatization\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "669cd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 Test the lemmatize_text function\n",
    "assert lemmatize_text('lopen') == ['lopen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d293b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 Load input from file and remove useless rows\n",
    "def load_and_clean_data(file_path):\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "    df = df[df['content'].apply(len) >= 200]\n",
    "    df = df[~df['Datum'].str.contains('1990')]\n",
    "    return df\n",
    "\n",
    "# Test the load_and_clean_data function with actual file path\n",
    "df = load_and_clean_data('C:/Users/xx/Downloads/Artikelen_Sanders.csv')\n",
    "\n",
    "# No assertion as it's a data preprocessing step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20c9a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 Preprocess content and title\n",
    "def preprocess_data(df):\n",
    "    # Clean text in content and title columns\n",
    "    df['clean_content'] = df['content'].apply(clean_text)\n",
    "    df['clean_title'] = df['Titel'].apply(clean_text)\n",
    "    \n",
    "    # Lowercase text\n",
    "    df['clean_content'] = df['clean_content'].apply(lambda x: x.lower())\n",
    "    df['clean_title'] = df['clean_title'].apply(lambda x: x.lower())\n",
    "    \n",
    "    # Tokenization\n",
    "    df['tokenized_content'] = df['clean_content'].apply(tokenize_text)\n",
    "    df['tokenized_title'] = df['clean_title'].apply(tokenize_text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    df['tokenized_content'] = df['tokenized_content'].apply(remove_stopwords)\n",
    "    df['tokenized_title'] = df['tokenized_title'].apply(remove_stopwords)\n",
    "    \n",
    "    # Lemmatization\n",
    "    df['lemmatized_content'] = df['clean_content'].apply(lemmatize_text)\n",
    "    df['lemmatized_title'] = df['clean_title'].apply(lemmatize_text)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2707b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13 Save preprocessed data to file\n",
    "def save_preprocessed_data(df, output_file):\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9efdc836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14 Test the preprocessing pipeline\n",
    "file_path = 'C:/Users/xx/Downloads/Artikelen_Sanders (1).csv'\n",
    "output_file_path = 'C:/Users/xx/Desktop/PrS_Artikelen_Sanders.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_clean_data(file_path)\n",
    "preprocessed_df = preprocess_data(df)\n",
    "save_preprocessed_data(preprocessed_df, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5caee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fd473bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stand-alone numbers in 'clean_content' column: []\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Function to check for stand-alone numbers in a DataFrame column\n",
    "\n",
    "def check_stand_alone_numbers(preprocessed_df, column_name):\n",
    "    stand_alone_numbers = []\n",
    "    for index, text in enumerate(preprocessed_df[column_name]):\n",
    "        numbers = re.findall(r'\\b\\d+\\b', text)\n",
    "        if numbers:\n",
    "            stand_alone_numbers.append((index, numbers))\n",
    "    return stand_alone_numbers\n",
    "\n",
    "# Test the check_stand_alone_numbers function on 'clean_content' column\n",
    "stand_alone_numbers_content = check_stand_alone_numbers(preprocessed_df, 'clean_content')\n",
    "print(\"Stand-alone numbers in 'clean_content' column:\", stand_alone_numbers_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18151aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stand-alone numbers in 'clean_title' column: []\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Function to check for stand-alone numbers in a DataFrame column\n",
    "\n",
    "def check_stand_alone_numbers(preprocessed_df, column_name):\n",
    "    stand_alone_numbers = []\n",
    "    for index, text in enumerate(preprocessed_df[column_name]):\n",
    "        numbers = re.findall(r'\\b\\d+\\b', text)\n",
    "        if numbers:\n",
    "            stand_alone_numbers.append((index, numbers))\n",
    "    return stand_alone_numbers\n",
    "\n",
    "# Test the check_stand_alone_numbers function on 'clean_content' column\n",
    "stand_alone_numbers_content = check_stand_alone_numbers(preprocessed_df, 'clean_title')\n",
    "print(\"Stand-alone numbers in 'clean_title' column:\", stand_alone_numbers_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f59f35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stand-alone letters in 'clean_title' column: [(266, ['n']), (437, ['n'])]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Function to check for stand-alone letters in a DataFrame column\n",
    "\n",
    "def check_stand_alone_letters(preprocessed_df, column_name):\n",
    "    stand_alone_letters = []\n",
    "    for index, text in enumerate(preprocessed_df[column_name]):\n",
    "        letters = re.findall(r'\\b[A-Za-z]\\b', text)\n",
    "        if letters:\n",
    "            stand_alone_letters.append((index, letters))\n",
    "    return stand_alone_letters\n",
    "\n",
    "# Test the check_stand_alone_letters function on 'clean_title' column\n",
    "stand_alone_letters_title = check_stand_alone_letters(preprocessed_df, 'clean_title')\n",
    "print(\"Stand-alone letters in 'clean_title' column:\", stand_alone_letters_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f98e2632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stand-alone letters in 'clean_content' column: [(0, ['n', 'z', 'n', 'n', 'n', 'n', 'n', 'n', 'p', 'n', 'n']), (6, ['k']), (7, ['e']), (8, ['n', 'v']), (9, ['c', 'n', 'k', 'g', 's', 'n']), (14, ['o', 'o']), (15, ['o']), (24, ['n']), (25, ['n']), (29, ['n', 'n']), (35, ['s', 'e', 'n']), (42, ['a', 'e']), (45, ['l']), (47, ['l']), (48, ['g']), (55, ['n']), (58, ['r']), (63, ['n']), (72, ['n']), (74, ['n', 'n']), (75, ['y']), (79, ['n']), (80, ['e']), (83, ['l', 'r']), (87, ['e', 'v']), (88, ['n']), (89, ['s', 'i']), (90, ['e']), (94, ['n']), (99, ['e']), (102, ['n']), (107, ['e']), (109, ['n', 'n', 'e', 'e', 'f', 'e', 'f']), (111, ['e']), (123, ['n']), (125, ['e', 'e', 'i']), (135, ['e']), (139, ['n']), (146, ['e', 'd', 'n']), (147, ['n', 'n', 'n']), (151, ['n']), (153, ['n', 'n', 'c', 'z']), (154, ['n']), (159, ['t', 'e']), (160, ['p']), (161, ['n', 'n']), (170, ['n']), (174, ['e', 'd']), (178, ['n']), (182, ['n', 'n', 'n', 'm']), (183, ['n']), (187, ['n']), (188, ['k']), (190, ['p', 'n']), (191, ['n']), (192, ['n', 'n']), (195, ['n']), (196, ['n', 'n', 'n', 'n']), (199, ['n']), (200, ['n']), (204, ['n', 'n', 'f', 'f']), (207, ['e']), (209, ['n']), (213, ['n']), (218, ['n', 'n']), (219, ['n']), (221, ['n']), (224, ['e', 's', 'n']), (230, ['n', 'n']), (231, ['n']), (232, ['n']), (237, ['n', 't', 'n']), (238, ['o', 'n', 'n', 'n']), (239, ['n', 'n', 's', 'n', 'n']), (240, ['r']), (243, ['n', 'n', 'n']), (244, ['m', 'h', 'p']), (250, ['d']), (251, ['v', 's', 's', 's', 'k']), (260, ['n', 'n', 'n', 'n', 'n']), (263, ['n', 'n']), (264, ['n']), (268, ['n']), (284, ['o', 'l']), (286, ['n']), (300, ['n']), (303, ['n']), (304, ['n']), (311, ['n']), (312, ['n', 'p']), (314, ['n']), (328, ['n']), (333, ['n']), (340, ['n']), (344, ['n']), (346, ['n']), (354, ['n']), (356, ['n']), (357, ['n']), (363, ['n']), (368, ['e']), (377, ['n']), (382, ['n']), (383, ['n']), (389, ['n']), (394, ['n']), (395, ['n', 'n']), (397, ['n']), (399, ['n']), (400, ['n', 'h']), (402, ['n']), (405, ['n']), (414, ['n']), (416, ['p']), (418, ['b']), (421, ['n', 'n']), (425, ['n']), (429, ['n']), (432, ['n', 'n']), (433, ['n']), (437, ['r']), (438, ['n']), (439, ['n']), (449, ['n']), (456, ['s']), (458, ['n', 'n']), (459, ['a']), (461, ['a', 'r']), (462, ['a']), (464, ['h']), (465, ['n']), (470, ['r']), (472, ['n']), (474, ['p']), (497, ['n']), (499, ['n']), (501, ['n']), (507, ['n']), (511, ['n', 'r', 'n', 'n', 'n', 'n', 'v', 'n', 'p', 'n', 'n', 'z']), (519, ['n']), (523, ['n']), (525, ['n']), (526, ['n']), (527, ['n']), (537, ['n', 'n']), (540, ['n']), (554, ['n']), (571, ['n']), (578, ['n', 'n']), (582, ['p']), (591, ['n']), (593, ['n', 'n']), (594, ['n']), (597, ['n']), (599, ['n']), (600, ['n']), (602, ['n', 'n', 'n', 'n']), (616, ['k']), (619, ['n', 'n']), (627, ['n'])]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Function to check for stand-alone letters in a DataFrame column\n",
    "\n",
    "def check_stand_alone_letters(preprocessed_df, column_name):\n",
    "    stand_alone_letters = []\n",
    "    for index, text in enumerate(preprocessed_df[column_name]):\n",
    "        letters = re.findall(r'\\b[A-Za-z]\\b', text)\n",
    "        if letters:\n",
    "            stand_alone_letters.append((index, letters))\n",
    "    return stand_alone_letters\n",
    "\n",
    "# Test the check_stand_alone_letters function on 'clean_title' column\n",
    "stand_alone_letters_title = check_stand_alone_letters(preprocessed_df, 'clean_content')\n",
    "print(\"Stand-alone letters in 'clean_content' column:\", stand_alone_letters_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b60047c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special characters in 'clean_content' column: []\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Function to check for special characters in a DataFrame column\n",
    "\n",
    "def check_special_characters(preprocessed_df, column_name):\n",
    "    special_characters = []\n",
    "    for index, text in enumerate(preprocessed_df[column_name]):\n",
    "        characters = re.findall(r'[^\\w\\s]', text)\n",
    "        if characters:\n",
    "            special_characters.append((index, characters))\n",
    "    return special_characters\n",
    "\n",
    "# Test the check_special_characters function on 'clean_content' column\n",
    "special_characters_content = check_special_characters(preprocessed_df, 'clean_content')\n",
    "print(\"Special characters in 'clean_content' column:\", special_characters_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1710526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special characters in 'clean_title' column: []\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Function to check for special characters in a DataFrame column\n",
    "\n",
    "def check_special_characters(df, column_name):\n",
    "    special_characters = []\n",
    "    for index, text in enumerate(df[column_name]):\n",
    "        characters = re.findall(r'[^\\w\\s]', text)\n",
    "        if characters:\n",
    "            special_characters.append((index, characters))\n",
    "    return special_characters\n",
    "\n",
    "# Test the check_special_characters function on 'clean_content' column\n",
    "special_characters_content = check_special_characters(preprocessed_df, 'clean_title')\n",
    "print(\"Special characters in 'clean_title' column:\", special_characters_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "257182b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact row for 'clean_title' column:\n",
      "blonde wervelwind\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact row for 'clean_title' column:\")\n",
    "print(preprocessed_df.loc[266, 'clean_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bdbe42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact row for 'Titel' column:\n",
      "DE BLONDE WERVELWIND\n"
     ]
    }
   ],
   "source": [
    "print(\"Exact row for 'Titel' column:\")\n",
    "print(preprocessed_df.loc[266, 'Titel'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
